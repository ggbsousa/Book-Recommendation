{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recommendation systems are a collection of algorithms used to recommend items to users based on information taken from the user. These systems have become ubiquitous can be commonly seen in online stores, movies databases and job finders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Acquiring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To acquire and extract the data, simply run the following Bash scripts:  \n",
    "Dataset acquired from [Book Crossing](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget -O bookdataset.zip http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip\n",
    "!unzip -o bookdataset.zip -d /resources/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to start working with the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get all of the imports out of the way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dataframe manipulation library\n",
    "import pandas as pd\n",
    "#Math functions, we'll only need the sqrt function so let's import only that\n",
    "from math import sqrt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read each file into their Dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Storing the movie information into a pandas dataframe\n",
    "books_df = pd.read_csv('/resources/data/BX-Books.csv', sep='\";\"')\n",
    "#Storing the user information into a pandas dataframe\n",
    "ratings_df = pd.read_csv('/resources/data/BX-Book-Ratings.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by having you take a peek at how the dataset is organized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#You code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlight the green box below for the answer\n",
    "<Oops! If you can read this, you can press Shift+Enter to convert this cell back to text.>\n",
    "<p style= \"padding: 6px; background-color: white\n",
    "; border: green 2px solid\"> \n",
    "<font color = \"white\">\n",
    "\n",
    "#Head is a function that gets the first N rows of a dataframe. N's default is 5. <br>\n",
    "books_df.head()\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each book has a unique ISBN, title, author, year of publication, publisher and three images of the book's cover in varying sizes. Let's first rename the columns to make them easier to access and also remove any unicode characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#New column names\n",
    "books_df.columns = ['ISBN', 'Title', 'Author', 'Year', 'Publisher', 'ImageS', 'ImageM', 'ImageL']\n",
    "#Applying a lambda function that removes unicode characters and strips the strings of any whitespace before or after\n",
    "#the resulting string\n",
    "books_df['Title'] = books_df['Title'].apply(lambda x: x.decode('unicode_escape').encode('ascii', 'ignore').strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's your turn! Finish cleaning up dataframe by removing quotation marks from the ISBN column and dropping the three unnecessary image columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlight the green box below for the answer\n",
    "<Oops! If you can read this, you can press Shift+Enter to convert this cell back to text.>\n",
    "<p style= \"padding: 6px; background-color: white\n",
    "; border: green 2px solid\"> \n",
    "<font color = \"white\">\n",
    "\n",
    "#Dropping the three image columns <br>\n",
    "books_df = books_df.drop('ImageS', 1) <br>\n",
    "books_df = books_df.drop('ImageM', 1) <br>\n",
    "books_df = books_df.drop('ImageL', 1) <br>\n",
    "#Removing the quotes from the ISBN column <br>\n",
    "books_df['ISBN'] = books_df['ISBN'].str.replace('\"', '') <br>\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the final books dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "books_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the ratings dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every row in the ratings dataframe has a user id associated with at least one book's unique ISBN and its given rating varying from 0 to 10.\n",
    "\n",
    "Let's just change the name of the columns for ease of access in the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_df.columns = ['UserID', 'ISBN', 'Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how the final ratings Dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start building a recommendation system.\n",
    "\n",
    "Here's the user we'll be recommendation books to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buffer = [\n",
    "            {'Title':'Complete Sherlock Holmes', 'Rating':8},\n",
    "            {'Title':\"The Hitchhiker's Guide to the Galaxy\", 'Rating':10},\n",
    "            {'Title':'Pride and Prejudice', 'Rating':6},\n",
    "            {'Title':'The Adventures of Tom Sawyer', 'Rating':5},\n",
    "            {'Title':'You Can Surf the Net: Your Guide to the World of the Internet', 'Rating':3}\n",
    "         ] \n",
    "inputUser = pd.DataFrame(buffer)\n",
    "inputUser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add rating to input user\n",
    "With the input complete, let's extract the input books's ISBNs from the books dataframe and add them into our input.\n",
    "\n",
    "We can achieve this by first filtering out the rows that contain the input books's title and then merging this subset with the input dataframe. We also drop unnecessary columns like the Author, Year and Publisher to save on memory space.\n",
    "\n",
    "Try implementing this part yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n",
    "#1: Implement a way of retrieving information of books inserted through the input from the main Books dataframe and store it\n",
    "\n",
    "#2: Get the stored information and merge it with the input\n",
    "\n",
    "#3: Drop the Author, Year and Publisher columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlight the green box below for the answer\n",
    "<Oops! If you can read this, you can press Shift+Enter to convert this cell back to text.>\n",
    "<p style= \"padding: 6px; background-color: white\n",
    "; border: green 2px solid\"> \n",
    "<font color = \"white\">\n",
    "\n",
    "#Filtering out the books by title <br>\n",
    "inputId = books_df[books_df['Title'].isin(inputUser['Title'].tolist())]<br>\n",
    "#Then merging it so we can get the ISBN. It's implicitly merging it by title.<br>\n",
    "inputUser = pd.merge(inputId, inputUser)<br>\n",
    "inputUser = inputUser.drop('Author', 1).drop('Year', 1).drop('Publisher', 1)<br>\n",
    "#Final input dataframe<br>\n",
    "#If a book you added in above isn't here, then it might not be in the original <br>\n",
    "#dataframe or it might spelled differently, please check capitalisation.<br>\n",
    "inputUser.head()<br>\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputUser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The users have read the same books\n",
    "Now with the book ISBN's in our input, we can now get the subset of users that have read and reviewed the movies in our input.\n",
    "\n",
    "Try implementing this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Store the subset of users that have read the same books as our input in the variable below\n",
    "userSubset = #Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlight the green box below for the answer\n",
    "<Oops! If you can read this, you can press Shift+Enter to convert this cell back to text.>\n",
    "<p style= \"padding: 6px; background-color: white\n",
    "; border: green 2px solid\"> \n",
    "<font color = \"white\">\n",
    "#Filtering out users that have watched movies that the input has watched and storing it <br>\n",
    "userSubset = ratings_df[ratings_df['ISBN'].isin(inputUser['ISBN'].tolist())] <br> \n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now group up the rows by user ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Groupby creates several sub dataframes where they all have the same value in the column specified as the parameter\n",
    "userSubsetGroup = userSubset.groupby(['UserID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one of the users, e.g. the one with UserID=11676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'userSubsetGroup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d1e1bd2546bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muserSubsetGroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11676\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'userSubsetGroup' is not defined"
     ]
    }
   ],
   "source": [
    "userSubsetGroup.get_group(11676)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also sort these groups so the users that share the most books in common with the input have higher priority. This provides a richer recommendation since we won't go through every single user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sorting it so users with most books in common with the input will have priority\n",
    "userSubsetGroup = sorted(userSubsetGroup,  key=lambda x: len(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at the first user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userSubsetGroup[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will select a subset of users to iterate through. This limit is imposed because we don't want to waste too much time going through every single user.\n",
    "\n",
    "Try implementing this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simply subset the first 100 users from our group\n",
    "userSubsetGroup = #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlight the green box below for the answer\n",
    "<Oops! If you can read this, you can press Shift+Enter to convert this cell back to text.>\n",
    "<p style= \"padding: 6px; background-color: white\n",
    "; border: green 2px solid\"> \n",
    "<font color = \"white\">\n",
    "userSubsetGroup = userSubsetGroup[0:100]\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we calculate the Pearson Correlation between input user and subset group, and store it in a dictionary, where the key is the user Id and the value is the coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Store the Pearson Correlation in a dictionary, where the key is the user Id and the value is the coefficient\n",
    "pearsonCorrelationDict = {}\n",
    "\n",
    "#For every user group in our subset\n",
    "for name, group in userSubsetGroup:\n",
    "    #Let's start by sorting the input and current user group so the values aren't mixed up later on\n",
    "    group = group.sort_values(by='ISBN')\n",
    "    inputUser = inputUser.sort_values(by='ISBN')\n",
    "    #Get the N for the formula\n",
    "    nRatings = len(group)\n",
    "    #Get the review scores for the books that they both have in common\n",
    "    temp_df = inputUser[inputUser['ISBN'].isin(group['ISBN'].tolist())]\n",
    "    #And then store them in a temporary buffer variable in a list format to facilitate future calculations\n",
    "    tempRatingList = temp_df['Rating'].tolist()\n",
    "    #Let's also put the current user group reviews in a list format\n",
    "    tempGroupList = group['Rating'].tolist()\n",
    "    #Now let's calculate the pearson correlation between two users, so called, x and y\n",
    "    Sxx = sum([i**2 for i in tempRatingList]) - pow(sum(tempRatingList),2)/float(nRatings)\n",
    "    Syy = sum([i**2 for i in tempGroupList]) - pow(sum(tempGroupList),2)/float(nRatings)\n",
    "    Sxy = sum( i*j for i, j in zip(tempRatingList, tempGroupList)) - sum(tempRatingList)*sum(tempGroupList)/float(nRatings)\n",
    "    \n",
    "    #If the denominator is different than zero, then divide, else, 0 correlation.\n",
    "    if Sxx != 0 and Syy != 0:\n",
    "        pearsonCorrelationDict[name] = Sxy/sqrt(Sxx*Syy)\n",
    "    else:\n",
    "        pearsonCorrelationDict[name] = 0\n",
    "pearsonDF=pd.DataFrame(pearsonCorrelationDict.items(), columns=['UserID', 'similarityIndex'])\n",
    "pearsonDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The top x similar users to input user\n",
    "Now let's get the top 50 users that are most similar to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topUsers = pearsonDF.sort_values(by='similarityIndex', ascending=False)[0:50]\n",
    "topUsers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start recommending books to the input user.\n",
    "\n",
    "#### Rating of selected users to all books\n",
    "We're going to do this by taking the weighted average of the ratings of the books using the Pearson Correlation as the weight. But to do this, we first need to get the books read by the users in our __pearsonDF__ from the ratings dataframe and then store their correlation in a new column called \"similarityIndex\". This is achieved below by merging these two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topUsersRating = topUsers.merge(ratings_df, left_on='UserID', right_on='UserID', how='inner')\n",
    "topUsersRating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we need to do is simply multiply the book rating by its weight (The similarity index), then sum up the new ratings and divide it by the sum of the weights.\n",
    "\n",
    "We can easily do this by simply multiplying two columns, then grouping up the dataframe by ISBN and then dividing two columns:\n",
    "\n",
    "It shows the idea of all similar users to candidate movies for the input user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Multiplies the similarity by the user's ratings\n",
    "topUsersRating['weightedRating'] = topUsersRating['similarityIndex']*topUsersRating['Rating']\n",
    "topUsersRating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Applies a sum to the topUsers after grouping it up by userId\n",
    "tempTopUsersRating = topUsersRating.groupby('ISBN').sum()[['similarityIndex','weightedRating']]\n",
    "tempTopUsersRating.columns = ['sum_similarityIndex','sum_weightedRating']\n",
    "tempTopUsersRating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates an empty dataframe\n",
    "recommendation_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the weighted average division!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simply apply the division using the correct columns\n",
    "recommendation_df['weighted average recommendation score'] = #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlight the green box below for the answer\n",
    "<Oops! If you can read this, you can press Shift+Enter to convert this cell back to text.>\n",
    "<p style= \"padding: 6px; background-color: white\n",
    "; border: green 2px solid\"> \n",
    "<font color = \"white\">\n",
    "#Now we take the weighted average <br>\n",
    "recommendation_df['weighted average recommendation score'] = tempTopUsersRating['sum_weightedRating'] / tempTopUsersRating['sum_similarityIndex'] <br>\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommendation_df['ISBN'] = tempTopUsersRating.index\n",
    "recommendation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's sort it and see the top 8 books that the algorithm recommended!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\n",
    "recommendation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_df.loc[books_df['ISBN'].isin(recommendation_df.head(8)['ISBN'].tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Gabriel Garcez Barros Sousa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[Book Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)\n",
    "\n",
    "[Collaborative Filtering Recommender Systems](http://files.grouplens.org/papers/FnT%20CF%20Recsys%20Survey.pdf)\n",
    "\n",
    "[Pandas Documentation](http://pandas.pydata.org/pandas-docs/stable/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
